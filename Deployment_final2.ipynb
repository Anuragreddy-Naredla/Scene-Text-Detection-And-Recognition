{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhUrPlcD-o-v",
    "outputId": "2cebc622-536d-4731-8614-9dd58c9d484a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMgwc8-Z-yBO",
    "outputId": "3754249c-6a0f-439f-acf7-f50d3398f9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import glob\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as Patches\n",
    "from shapely.geometry import Polygon\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import threading\n",
    "import shutil\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as Patches\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import UpSampling2D,concatenate,Conv2D,BatchNormalization,Activation,Lambda,MaxPooling2D,Dense,Bidirectional\n",
    "from shapely.geometry import Polygon\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import multiprocessing\n",
    "import scipy.io as sio\n",
    "try:\n",
    "    import queue\n",
    "except ImportError:\n",
    "    import Queue as queue\n",
    "#https://github.com/argman/EAST/blob/master/icdar.py\n",
    "def sort_rectangle(poly):\n",
    "    '''sort the four coordinates of the polygon, points in poly should be sorted clockwise'''\n",
    "    # First find the lowest point\n",
    "    p_lowest = np.argmax(poly[:, 1])\n",
    "    if np.count_nonzero(poly[:, 1] == poly[p_lowest, 1]) == 2:\n",
    "        # if the bottom line is parallel to x-axis, then p0 must be the upper-left corner\n",
    "        p0_index = np.argmin(np.sum(poly, axis=1))\n",
    "        p1_index = (p0_index + 1) % 4\n",
    "        p2_index = (p0_index + 2) % 4\n",
    "        p3_index = (p0_index + 3) % 4\n",
    "        return poly[[p0_index, p1_index, p2_index, p3_index]], 0.\n",
    "    else:\n",
    "        # find the point that sits right to the lowest point\n",
    "        p_lowest_right = (p_lowest - 1) % 4\n",
    "        p_lowest_left = (p_lowest + 1) % 4\n",
    "        angle = np.arctan(-(poly[p_lowest][1] - poly[p_lowest_right][1])/(poly[p_lowest][0] - poly[p_lowest_right][0]))\n",
    "        # assert angle > 0\n",
    "        if angle <= 0:\n",
    "            print(angle, poly[p_lowest], poly[p_lowest_right])\n",
    "        if angle/np.pi * 180 > 45:\n",
    "            #this point is p2\n",
    "            p2_index = p_lowest\n",
    "            p1_index = (p2_index - 1) % 4\n",
    "            p0_index = (p2_index - 2) % 4\n",
    "            p3_index = (p2_index + 1) % 4\n",
    "            return poly[[p0_index, p1_index, p2_index, p3_index]], -(np.pi/2 - angle)\n",
    "        else:\n",
    "            # this point is p3\n",
    "            p3_index = p_lowest\n",
    "            p0_index = (p3_index + 1) % 4\n",
    "            p1_index = (p3_index + 2) % 4\n",
    "            p2_index = (p3_index + 3) % 4\n",
    "            return poly[[p0_index, p1_index, p2_index, p3_index]], angle\n",
    "#https://github.com/argman/EAST/blob/master/icdar.py\n",
    "def restore_rectangle_rbox(origin, geometry):\n",
    "    ''' Resotre rectangle tbox'''\n",
    "    d = geometry[:, :4]\n",
    "    angle = geometry[:, 4]\n",
    "    # for angle > 0\n",
    "    origin_0 = origin[angle >= 0]\n",
    "    d_0 = d[angle >= 0]\n",
    "    angle_0 = angle[angle >= 0]\n",
    "    if origin_0.shape[0] > 0:\n",
    "        p = np.array([np.zeros(d_0.shape[0]), -d_0[:, 0] - d_0[:, 2],\n",
    "                      d_0[:, 1] + d_0[:, 3], -d_0[:, 0] - d_0[:, 2],\n",
    "                      d_0[:, 1] + d_0[:, 3], np.zeros(d_0.shape[0]),\n",
    "                      np.zeros(d_0.shape[0]), np.zeros(d_0.shape[0]),\n",
    "                      d_0[:, 3], -d_0[:, 2]])\n",
    "        p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n",
    "\n",
    "        rotate_matrix_x = np.array([np.cos(angle_0), np.sin(angle_0)]).transpose((1, 0))\n",
    "        rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n",
    "\n",
    "        rotate_matrix_y = np.array([-np.sin(angle_0), np.cos(angle_0)]).transpose((1, 0))\n",
    "        rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n",
    "\n",
    "        p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
    "        p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
    "\n",
    "        p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n",
    "\n",
    "        p3_in_origin = origin_0 - p_rotate[:, 4, :]\n",
    "        new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n",
    "        new_p1 = p_rotate[:, 1, :] + p3_in_origin\n",
    "        new_p2 = p_rotate[:, 2, :] + p3_in_origin\n",
    "        new_p3 = p_rotate[:, 3, :] + p3_in_origin\n",
    "\n",
    "        new_p_0 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n",
    "                                  new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n",
    "    else:\n",
    "        new_p_0 = np.zeros((0, 4, 2))\n",
    "    # for angle < 0\n",
    "    origin_1 = origin[angle < 0]\n",
    "    d_1 = d[angle < 0]\n",
    "    angle_1 = angle[angle < 0]\n",
    "    if origin_1.shape[0] > 0:\n",
    "        p = np.array([-d_1[:, 1] - d_1[:, 3], -d_1[:, 0] - d_1[:, 2],\n",
    "                      np.zeros(d_1.shape[0]), -d_1[:, 0] - d_1[:, 2],\n",
    "                      np.zeros(d_1.shape[0]), np.zeros(d_1.shape[0]),\n",
    "                      -d_1[:, 1] - d_1[:, 3], np.zeros(d_1.shape[0]),\n",
    "                      -d_1[:, 1], -d_1[:, 2]])\n",
    "        p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n",
    "\n",
    "        rotate_matrix_x = np.array([np.cos(-angle_1), -np.sin(-angle_1)]).transpose((1, 0))\n",
    "        rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n",
    "\n",
    "        rotate_matrix_y = np.array([np.sin(-angle_1), np.cos(-angle_1)]).transpose((1, 0))\n",
    "        rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n",
    "\n",
    "        p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
    "        p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
    "\n",
    "        p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n",
    "\n",
    "        p3_in_origin = origin_1 - p_rotate[:, 4, :]\n",
    "        new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n",
    "        new_p1 = p_rotate[:, 1, :] + p3_in_origin\n",
    "        new_p2 = p_rotate[:, 2, :] + p3_in_origin\n",
    "        new_p3 = p_rotate[:, 3, :] + p3_in_origin\n",
    "\n",
    "        new_p_1 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n",
    "                                  new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n",
    "    else:\n",
    "        new_p_1 = np.zeros((0, 4, 2))\n",
    "    return np.concatenate([new_p_0, new_p_1])\n",
    "def restore_rectangle(origin, geometry):\n",
    "    return restore_rectangle_rbox(origin, geometry)\n",
    "def generate_roiRotatePara(box, angle, expand_w = 60):\n",
    "    '''Generate all ROI Parameterts'''\n",
    "    p0_rect, p1_rect, p2_rect, p3_rect = box\n",
    "    cxy = (p0_rect + p2_rect) / 2.\n",
    "    size = np.array([np.linalg.norm(p0_rect - p1_rect), np.linalg.norm(p0_rect - p3_rect)])\n",
    "    rrect = np.concatenate([cxy, size])\n",
    "\n",
    "    box=np.array(box)\n",
    "\n",
    "    points=np.array(box, dtype=np.int32)\n",
    "    xmin=np.min(points[:,0])\n",
    "    xmax=np.max(points[:,0])\n",
    "    ymin=np.min(points[:,1])\n",
    "    ymax=np.max(points[:,1])\n",
    "    bbox = np.array([xmin, ymin, xmax, ymax])\n",
    "    if np.any(bbox < -expand_w):\n",
    "        return None\n",
    "    \n",
    "    rrect[:2] -= bbox[:2]\n",
    "    rrect[:2] -= rrect[2:] / 2\n",
    "    rrect[2:] += rrect[:2]\n",
    "\n",
    "    bbox[2:] -= bbox[:2]\n",
    "\n",
    "    rrect[::2] = np.clip(rrect[::2], 0, bbox[2])\n",
    "    rrect[1::2] = np.clip(rrect[1::2], 0, bbox[3])\n",
    "    rrect[2:] -= rrect[:2]\n",
    "    \n",
    "    return bbox.astype(np.int32), rrect.astype(np.int32), - angle\n",
    "def restore_roiRotatePara(box):\n",
    "    rectange, rotate_angle = sort_rectangle(box)\n",
    "    return generate_roiRotatePara(rectange, rotate_angle)\n",
    "#https://github.com/argman/EAST/blob/master/eval.py\n",
    "def sort_poly(p):\n",
    "  min_axis = np.argmin(np.sum(p, axis=1))\n",
    "  p = p[[min_axis, (min_axis+1)%4, (min_axis+2)%4, (min_axis+3)%4]]\n",
    "  if abs(p[0, 0] - p[1, 0]) > abs(p[0, 1] - p[1, 1]):\n",
    "    return p\n",
    "  else:\n",
    "    return p[[0, 3, 2, 1]]\n",
    "#https://github.com/argman/EAST/blob/master/locality_aware_nms.py\n",
    "def intersection(g, p):\n",
    "    g = Polygon(g[:8].reshape((4, 2)))\n",
    "    p = Polygon(p[:8].reshape((4, 2)))\n",
    "    if not g.is_valid or not p.is_valid:\n",
    "        return 0\n",
    "    inter = Polygon(g).intersection(Polygon(p)).area\n",
    "    union = g.area + p.area - inter\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return inter/union\n",
    "#https://github.com/argman/EAST/blob/master/locality_aware_nms.py\n",
    "def weighted_merge(g, p):\n",
    "    g[:8] = (g[8] * g[:8] + p[8] * p[:8])/(g[8] + p[8])\n",
    "    g[8] = (g[8] + p[8])\n",
    "    return g\n",
    "#https://github.com/argman/EAST/blob/master/locality_aware_nms.py\n",
    "def standard_nms(S, thres):\n",
    "    order = np.argsort(S[:, 8])[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        ovr = np.array([intersection(S[i], S[t]) for t in order[1:]])\n",
    "\n",
    "        inds = np.where(ovr <= thres)[0]\n",
    "        order = order[inds+1]\n",
    "\n",
    "    return S[keep]\n",
    "#https://github.com/argman/EAST/blob/master/locality_aware_nms.py\n",
    "def nms_locality(polys, thres=0.3):\n",
    "    '''\n",
    "    :param polys: a N*9 numpy array. first 8 coordinates, then prob\n",
    "    :return: boxes after nms\n",
    "    '''\n",
    "    S = []\n",
    "    p = None\n",
    "  \n",
    "    for g in polys:\n",
    "        if p is not None and intersection(g, p) > thres:\n",
    "        \n",
    "            p = weighted_merge(g, p)\n",
    "        else:\n",
    "            if p is not None:\n",
    "                S.append(p)\n",
    "            p = g\n",
    "  \n",
    "    if p is not None:\n",
    "        S.append(p)\n",
    "\n",
    "    if len(S) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    return standard_nms(np.array(S), thres)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Pipeline(img):\n",
    "  start_time=time.time()\n",
    "  \n",
    "  #1.Text Detection\n",
    "  img=cv2.resize(img,(512,512))\n",
    "  ii=model.predict(np.expand_dims(img,axis=0))\n",
    "  score_map=ii[0][:,:,0]\n",
    "  geo_map=ii[0][:,:,1:]\n",
    "  for ind in [0,1,2,3,4]:\n",
    "    geo_map[:,:,ind]*=score_map\n",
    "\n",
    "  #2.ROI Rotate  \n",
    "  score_map_thresh=0.5\n",
    "  box_thresh=0.1 \n",
    "  nms_thres=0.2\n",
    "  if len(score_map.shape) == 4:\n",
    "    score_map = score_map[0, :, :, 0]\n",
    "    geo_map = geo_map[0, :, :, :]\n",
    "\n",
    "  # filter the score map\n",
    "  xy_text = np.argwhere(score_map > score_map_thresh)\n",
    "\n",
    "  # sort the text boxes via the y axis\n",
    "  xy_text = xy_text[np.argsort(xy_text[:, 0])]\n",
    "\n",
    "  # restore\n",
    "  text_box_restored = restore_rectangle(xy_text[:, ::-1], geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2\n",
    "  boxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32)\n",
    "  boxes[:, :8] = text_box_restored.reshape((-1, 8))\n",
    "  boxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]]\n",
    "  boxes = nms_locality(boxes.astype(np.float64), nms_thres)\n",
    "  \n",
    "\n",
    "  # here we filter some low score boxes by the average score map, this is different from the orginal paper\n",
    "  for i, box in enumerate(boxes):\n",
    "    mask = np.zeros_like(score_map, dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32), 1)\n",
    "    boxes[i, 8] = cv2.mean(score_map, mask)[0]\n",
    "    if i==4:\n",
    "      break\n",
    "  if len(boxes)>0:\n",
    "    boxes = boxes[boxes[:, 8] > box_thresh]\n",
    "  boxes[:,:8:2] = np.clip(boxes[:,:8:2], 0, 512 - 1)\n",
    "  boxes[:,1:8:2] = np.clip(boxes[:,1:8:2], 0, 512 - 1)  \n",
    "  res = []\n",
    "  result = []\n",
    "  if len(boxes)>0:\n",
    "    for box in boxes:\n",
    "      box_ =  box[:8].reshape((4, 2))\n",
    "      if np.linalg.norm(box_[0] - box_[1]) < 8 or np.linalg.norm(box_[3]-box_[0]) < 8:\n",
    "        continue\n",
    "      result.append(box_)\n",
    "  res.append(np.array(result, np.float32))   \n",
    "\n",
    "  box_index = []\n",
    "  brotateParas = []\n",
    "  filter_bsharedFeatures = []\n",
    "  for i in range(len(res)):\n",
    "    rotateParas = []\n",
    "    rboxes=res[i]\n",
    "    txt=[]\n",
    "    for j, rbox in enumerate(rboxes):\n",
    "      para = restore_roiRotatePara(rbox)\n",
    "      if para and min(para[1][2:]) > 8:\n",
    "        rotateParas.append(para)\n",
    "        box_index.append((i, j))\n",
    "    pts=[]   \n",
    "    \n",
    "    \n",
    "    #3. Text Recognition (From boxes given by Text Detection+ROI Rotate) \n",
    "    if len(rotateParas) > 0:\n",
    "      for num in range(len(rotateParas)):\n",
    "        text=\"\"\n",
    "        out=rotateParas[num][0]\n",
    "        crop=rotateParas[num][1]\n",
    "        points=np.array([[out[0],out[1]],[out[0]+out[2],out[1]],[out[0]+out[2],out[1]+out[3]],[out[0],out[1]+out[3]]])\n",
    "        angle=rotateParas[num][2] \n",
    "        img1=tf.image.crop_to_bounding_box(img,out[1],out[0],out[3],out[2])\n",
    "        img2=tf.keras.preprocessing.image.random_rotation(img1,angle)\n",
    "        img2=tf.image.crop_to_bounding_box(img2,crop[1],crop[0],crop[3],crop[2]).numpy()\n",
    "        img2=cv2.resize(img2,(128,64))\n",
    "        img2=cv2.detailEnhance(img2)\n",
    "        ii=recognizer_model.predict(np.expand_dims(img2,axis=0))\n",
    "        arr=tf.keras.backend.ctc_decode(ii,np.ones((1),'int8')*64,)\n",
    "        for val in arr[0][0].numpy()[0]:\n",
    "          if val==-1:\n",
    "            break\n",
    "          else:\n",
    "            text+=index_char[val]\n",
    "        txt.append(text)\n",
    "        pts.append(points)\n",
    "    \n",
    "    # 4. Labeling detected and Recognized Text in Image  \n",
    "    for i in range(len(txt)):\n",
    "      cv2.polylines(img,[pts[i]],isClosed=True,color=(0,255,0),thickness=1)\n",
    "    end_time=time.time()\n",
    "    print(\"Time Taken By Pipeline=\"+str(end_time-start_time)+\" seconds\")  \n",
    "    return img,txt    \n",
    "\n",
    "\n",
    "@st.cache(show_spinner=False)\n",
    "def detection():\n",
    "  resnet = ResNet50(input_shape=(512, 512, 3), weights='imagenet', include_top=False)\n",
    "  tf.keras.backend.clear_session()\n",
    "  x = resnet.get_layer('conv5_block3_out').output\n",
    "\n",
    "  x = UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_1')(x)\n",
    "  x = concatenate([x, resnet.get_layer('conv4_block6_out').output], axis=3)\n",
    "  x = Conv2D(128, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "  x = BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "  x = BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "  x = Activation('relu')(x)\n",
    "\n",
    "  x = tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_2')(x)\n",
    "  x = tf.keras.layers.concatenate([x, resnet.get_layer('conv3_block4_out').output], axis=3)\n",
    "  x = tf.keras.layers.Conv2D(64, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "  x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "  x = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "  x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "  x = tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',name='resize_3')(x)\n",
    "  x = tf.keras.layers.concatenate([x, resnet.get_layer('conv2_block3_out').output], axis=3)\n",
    "  x = tf.keras.layers.Conv2D(32, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "  x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "  x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "  x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "  x = Conv2D(32,kernel_size=3, strides=1,padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "  x = BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = UpSampling2D(size=(4,4),interpolation='bilinear',data_format='channels_last',name='extra')(x)\n",
    "\n",
    "  pred_score_map = Conv2D(1, (1, 1), activation=tf.nn.sigmoid, name='pred_score_map',padding='same')(x)\n",
    "  rbox_geo_map = Conv2D(4, (1, 1), activation=tf.nn.sigmoid, name='rbox_geo_map')(x)\n",
    "  rbox_geo_map = Lambda(lambda x: x * 512)(rbox_geo_map)\n",
    "  angle_map = Conv2D(1, (1, 1), activation=tf.nn.sigmoid, name='rbox_angle_map')(x)\n",
    "  angle_map = Lambda(lambda x: (x - 0.5) * np.pi / 2)(angle_map)\n",
    "  output = concatenate([pred_score_map,rbox_geo_map, angle_map], axis=3, name='pred_map')\n",
    "\n",
    "\n",
    "  model = tf.keras.models.Model(inputs=resnet.input, outputs= output,name='EAST')\n",
    "  for layers in resnet.layers:\n",
    "    layers.trainable=False  \n",
    "  model.load_weights('/content/drive/MyDrive/resnet50_35epochs.h5')\n",
    "  return model\n",
    "\n",
    "\n",
    "@st.cache(show_spinner=False)\n",
    "def recognition():\n",
    "  #Building the Convolution Recurrent Neural Network Architecture for text Recognition.\n",
    "  #https://github.com/qjadud1994/CRNN-Keras/blob/master/Model_GRU.py\n",
    "  inputs = tf.keras.layers.Input(name='the_input', shape=(64,128,3), dtype='float32')  \n",
    "\n",
    "  #CONVOLUTION LAYER1\n",
    "  inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  \n",
    "  #BATCHNORM\n",
    "  inner = BatchNormalization()(inner)\n",
    "  #ACCTIVATION\n",
    "  inner = Activation('relu')(inner)\n",
    "  #MAXPOOLING1\n",
    "  inner = MaxPooling2D(pool_size=(2, 1), name='max1')(inner)\n",
    "\n",
    "  #CONVOLUTION LAYER2\n",
    "  inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  \n",
    "  #BATCHNORM\n",
    "  inner = BatchNormalization()(inner)\n",
    "  #ACTIVATION\n",
    "  inner = Activation('relu')(inner)\n",
    "  #MAXPOOLING2\n",
    "  inner = MaxPooling2D(pool_size=(2, 1), name='max2')(inner)\n",
    "\n",
    "  #CONVOLUTION LAYER3 \n",
    "  inner = Conv2D(32, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  \n",
    "  #BATCHNORM\n",
    "  inner = BatchNormalization()(inner)\n",
    "  #ACTIVATION\n",
    "  inner =Activation('relu')(inner)\n",
    "\n",
    "  #CONVOLUTION LAYER4\n",
    "  inner = Conv2D(32, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  \n",
    "  #BATCHNORM\n",
    "  inner = BatchNormalization()(inner)\n",
    "  #ACTIVATION\n",
    "  inner = Activation('relu')(inner)\n",
    "  #MAXPOOLING3\n",
    "  inner = MaxPooling2D(pool_size=(2, 1), name='max3')(inner)  \n",
    "\n",
    "  #CONVOLUTION LAYER5\n",
    "  inner = Conv2D(32, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  \n",
    "  #BATCHNORM\n",
    "  inner = BatchNormalization()(inner)\n",
    "  #ACTIVATION\n",
    "  inner = Activation('relu')(inner)\n",
    "\n",
    "  #CONVOLUTION LAYER6\n",
    "  inner = Conv2D(32, (3, 3), padding='same', name='conv6')(inner) \n",
    "  #BATCHNORM  \n",
    "  inner = BatchNormalization()(inner)\n",
    "  #ACTIVATION\n",
    "  inner =Activation('relu')(inner)\n",
    "  #MAXPOOLING4\n",
    "  inner = MaxPooling2D(pool_size=(2, 1), name='max4')(inner)  \n",
    "\n",
    "  #CONVOLUTION LAYER7\n",
    "  inner = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', name='conv7')(inner) \n",
    "  #BATCHNORM\n",
    "  inner = BatchNormalization()(inner)\n",
    "  #ACTIVATION\n",
    "  inner = Activation('relu')(inner)\n",
    "  #Reshaping\n",
    "  inner = tf.keras.layers.Reshape(target_shape=((64,512)), name='reshape')(inner)  \n",
    "  #DENSE\n",
    "  inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner) \n",
    "\n",
    "  #Applying bi-directional GRU\n",
    "  out=Bidirectional(tf.keras.layers.GRU(32,return_sequences=True,go_backwards=True))(inner)\n",
    "  out=Bidirectional(tf.keras.layers.GRU(128,return_sequences=True,go_backwards=True))(out)\n",
    "  #DENSE\n",
    "  x=Dense(100)(out)#Here we hve given 100 because vocab size is 99 and 1 extra is for blank symbol\n",
    "  x=tf.keras.activations.softmax(x)\n",
    "  recognizer_model=tf.keras.models.Model(inputs,x)\n",
    "  recognizer_model.load_weights('/content/drive/MyDrive/recoginzer.h5')\n",
    "  return recognizer_model\n",
    "\n",
    "\n",
    "model = detection()\n",
    "recognizer_model = recognition()\n",
    "#Preparing vocabulary for Text Recognition Branch\n",
    "CHAR_VECTOR = \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZÉ´-~`<>'.:;^/|!?$%#@&*()[]{}_+=,\\\\\\\"\"\n",
    "NUM_CLASSES = len(CHAR_VECTOR) \n",
    "char_index={}\n",
    "index_char={}\n",
    "for i,val in enumerate(CHAR_VECTOR):\n",
    "  index_char[i+1]=val\n",
    "  char_index[val]=i+1\n",
    "\n",
    "st.title('scene TEXT Detection and Recognition')\n",
    "st.header('Enter the image')\n",
    "img=st.file_uploader('upload a image')\n",
    "if img:    \n",
    "  st.image(img,width=512)\n",
    "  image = Image.open(img)\n",
    "  img = np.array(image)\n",
    "  im,txt=Pipeline(img)\n",
    "  txt=','.join(txt)\n",
    "  im=cv2.resize(im,(512,400))\n",
    "  st.header('Resulted image')\n",
    "  st.image(im)\n",
    "  st.write(\"Predicted Text is :\",txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFCRISlAUBUP"
   },
   "source": [
    "#### Steps for building web app using streamlit and ngrok:\n",
    "    1.Register: https://dashboard.ngrok.com/get-started/setup\n",
    "    2.Create An Account on Ngrok which was from above link\n",
    "    2.Get Your Authentication Tokens\n",
    "    3.Copy and paste your authtoken in \"!ngrok authtoken\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REKz4ox1-3Mv",
    "outputId": "aa71b3ee-4222-4329-8028-f71da9e535fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
      "NgrokTunnel: \"http://1cf46551a750.ngrok.io\" -> \"http://localhost:80\"\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken **********************************************#Copy paste your token\n",
    "from pyngrok import ngrok\n",
    "public_url = ngrok.connect(port=80)\n",
    "print(public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOE-GNmU-3Qf",
    "outputId": "599a5987-42c7-4cb0-e90e-cc0b6470734b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:80\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.82.183.243:80\u001b[0m\n",
      "\u001b[0m\n",
      "2021-06-29 16:33:47.201574: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-29 16:33:48.660572: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-29 16:33:48.727266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:48.728289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-06-29 16:33:48.728367: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-29 16:33:48.810086: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-29 16:33:48.810191: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-29 16:33:48.932583: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-29 16:33:48.956848: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-29 16:33:49.166835: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-29 16:33:49.206590: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-29 16:33:49.210802: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-29 16:33:49.210943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:49.211955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:49.216196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-06-29 16:33:49.217073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:49.217874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-06-29 16:33:49.217990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:49.218939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:49.219732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-06-29 16:33:49.222980: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-29 16:33:51.584646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-29 16:33:51.584703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-06-29 16:33:51.584724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-06-29 16:33:51.584956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:51.586014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:51.586957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-29 16:33:51.587809: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-06-29 16:33:51.587888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15433 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n",
      "2021-06-29 16:34:06.371365: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-06-29 16:34:06.375125: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n",
      "2021-06-29 16:34:07.597379: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-29 16:34:08.688196: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\n",
      "2021-06-29 16:34:20.458731: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-29 16:34:21.709654: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "Time Taken By Pipeline=18.512219667434692 seconds\n",
      "Time Taken By Pipeline=1.7251660823822021 seconds\n",
      "Time Taken By Pipeline=0.4502859115600586 seconds\n"
     ]
    }
   ],
   "source": [
    "!export STREAMLIT_SERVER_PORT=80\n",
    "#running Script using streamlit:\n",
    "!streamlit run app.py --server.port 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbHNbf3imOnp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Deployment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
